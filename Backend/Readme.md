/Backend/
â”‚
â”œâ”€â”€ ğŸ“ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ“ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ historical.py       # Endpoints for historical data (from PostgreSQL)
â”‚   â””â”€â”€ ğŸ“ predictive/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ forecasts.py        # Endpoints for FUTURE on-demand forecasts
â”‚       â””â”€â”€ insights.py         # The "Why Engine" for interpretability
â”‚
â”œâ”€â”€ ğŸ“ config/
â”‚   â””â”€â”€ settings.py           # Your central Pydantic settings
â”‚
â”œâ”€â”€ ğŸ“ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py              # The Python class definition for YOUR HALSTM model
â”‚   â””â”€â”€ forecasting_service.py # The NEW, CORRECT service for live forecasting
â”‚
â”œâ”€â”€ ğŸ“ db/
â”‚   â””â”€â”€ postgres_client.py    # Your existing, perfect PostgreSQL connection manager
â”‚
â”œâ”€â”€ ğŸ“ models/                 # Model artifacts
â”‚   â”œâ”€â”€ best_ha_lstm.pth
â”‚   â”œâ”€â”€ target_scaler.pkl
â”‚   â””â”€â”€ feature_scaler.pkl
â”‚
â”œâ”€â”€ ğŸ“„ main.py                   # The main FastAPI application entry point
â””â”€â”€ ğŸ“„ pydantic_models.py         # Data contracts for your API


contextchain 

# Initialize a new pipeline with sub-schemas and ChromaDB
contextchain init --file schemas/my_pipeline.json --interactive

# Run a pipeline
contextchain run --pipeline-id my_pipeline

# Run a single task
contextchain run-task --pipeline-id my_pipeline --task_id 1

# Initialize a vector DB collection
contextchain vector init --collection my_collection

# Search in a vector DB collection
contextchain vector search --collection my_collection --query "example query"

# Setup a local LLM
contextchain llm setup --model mistral:7b