{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d46586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU device: NVIDIA RTX A6000\n",
      "GPU count: 1\n",
      "Current device: 0\n",
      "CUDA test operation successful: tensor([2., 3., 4.], device='cuda:0')\n",
      "NVIDIA-SMI output:\n",
      "Sat May 10 16:59:42 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  |   00000000:D5:00.0 Off |                    0 |\n",
      "| 30%   33C    P2             63W /  300W |     316MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "Total GPU memory: 44.45 GiB\n",
      "Allocated GPU memory: 0.00 GiB\n",
      "Reserved GPU memory: 0.00 GiB\n",
      "Python version: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "Python executable: /workspace/XAI-1/nvenv/bin/python\n",
      "PATH: /workspace/XAI-1/nvenv/bin:/root/.vscode-server/cli/servers/Stable-17baf841131aa23349f217ca7c570c76ee87b957/server/bin/remote-cli:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "Available disk space: 16.25 GiB\n",
      "Using device: cuda\n",
      "Cleared GPU memory cache\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from uuid import uuid4\n",
    "import warnings\n",
    "import subprocess\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced PyTorch and CUDA diagnostics\n",
    "def check_cuda_environment():\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available. This notebook requires a GPU.\")\n",
    "    \n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    \n",
    "    # Test CUDA operation\n",
    "    try:\n",
    "        test_tensor = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
    "        test_result = test_tensor + 1\n",
    "        print(f\"CUDA test operation successful: {test_result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"CUDA test operation failed: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Check NVIDIA driver and CUDA toolkit\n",
    "    try:\n",
    "        nvidia_smi = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "        print(\"NVIDIA-SMI output:\")\n",
    "        print(nvidia_smi.stdout)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run nvidia-smi: {e}\")\n",
    "    \n",
    "    # Check GPU memory\n",
    "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 2**30:.2f} GiB\")\n",
    "    print(f\"Allocated GPU memory: {torch.cuda.memory_allocated(0) / 2**30:.2f} GiB\")\n",
    "    print(f\"Reserved GPU memory: {torch.cuda.memory_reserved(0) / 2**30:.2f} GiB\")\n",
    "\n",
    "try:\n",
    "    check_cuda_environment()\n",
    "except Exception as e:\n",
    "    print(f\"Error with PyTorch or CUDA setup: {e}\")\n",
    "    print(\"Try reinstalling PyTorch: pip install torch==2.7.0 --index-url https://download.pytorch.org/whl/cu124\")\n",
    "    raise\n",
    "\n",
    "# Environment diagnostics\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"PATH: {os.environ.get('PATH')}\")\n",
    "print(f\"Available disk space: {shutil.disk_usage('/').free / (2**30):.2f} GiB\")\n",
    "\n",
    "# Check for module shadowing\n",
    "if os.path.exists('/workspace/XAI/torch.py') or os.path.exists('/workspace/XAI/torch.pyc'):\n",
    "    print(\"Warning: Found 'torch.py' or 'torch.pyc' in /workspace/XAI. Please rename or remove it.\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration (GPU only)\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Cleared GPU memory cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe58622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /workspace/XAI-1/Predict Future Sales/merged_data.csv\n",
      "Dataset shape: (2935849, 10)\n",
      "Columns: ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'item_cnt_day', 'item_name', 'item_category_id', 'item_category_name', 'shop_name']\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir=\"/workspace/data\", file_name=\"merged_data.csv\"):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    alt_path = \"/workspace/XAI-1/Predict Future Sales/merged_data.csv\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        if os.path.exists(alt_path):\n",
    "            file_path = alt_path\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File not found at {file_path} or {alt_path}\")\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Loaded data from {file_path}\")\n",
    "        print(f\"Dataset shape: {data.shape}\")\n",
    "        print(f\"Columns: {list(data.columns)}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load {file_path}: {e}\")\n",
    "    \n",
    "    # Verify expected columns\n",
    "    expected_columns = ['date', 'shop_id', 'item_id', 'item_name', 'item_cnt_day', 'item_price', 'item_category_id', 'shop_name', 'item_category_name', 'date_block_num']\n",
    "    missing_cols = [col for col in expected_columns if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing expected columns: {missing_cols}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95bd83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 16:59:49 - INFO - Initial columns kept: ['date', 'date_block_num', 'shop_id', 'item_id', 'item_category_id', 'item_cnt_day', 'item_price']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 16:59:49 - INFO - Records after removing invalid dates: 2935849\n",
      "2025-05-10 16:59:49 - INFO - Date conversion time: 0.34 seconds\n",
      "2025-05-10 16:59:50 - INFO - Duplicate records: 6\n",
      "2025-05-10 16:59:51 - INFO - Duplicate removal time: 1.48 seconds\n",
      "2025-05-10 16:59:51 - INFO - \n",
      "Missing values before processing:\n",
      "2025-05-10 16:59:51 - INFO - date                0\n",
      "date_block_num      0\n",
      "shop_id             0\n",
      "item_id             0\n",
      "item_price          0\n",
      "item_cnt_day        0\n",
      "item_category_id    0\n",
      "2025-05-10 16:59:51 - INFO - Missing value check time: 0.06 seconds\n",
      "2025-05-10 17:00:10 - INFO - Outliers detected: 170214 (5.80%)\n",
      "2025-05-10 17:00:10 - INFO - Winsorization time: 19.32 seconds\n",
      "2025-05-10 17:00:12 - INFO - Negative sales after processing: 0\n",
      "2025-05-10 17:00:12 - INFO - Negative sales handling time: 1.60 seconds\n",
      "2025-05-10 17:00:13 - INFO - Monthly sales shape: (1609122, 10)\n",
      "2025-05-10 17:00:13 - INFO - Aggregation time: 0.69 seconds\n",
      "2025-05-10 17:00:13 - INFO - Records after creating lag features and filling NA: 1609122\n",
      "2025-05-10 17:00:13 - INFO - Lag feature creation time: 0.70 seconds\n",
      "2025-05-10 17:00:14 - INFO - Saved unscaled data to /workspace/processed_data/monthly_sales_unscaled.parquet\n",
      "2025-05-10 17:00:14 - INFO - Training data shape for scaler fit: (1514429, 12)\n",
      "2025-05-10 17:00:14 - INFO - Pre-scaling training data stats:\n",
      "2025-05-10 17:00:14 - INFO -   item_cnt_day_winsor: mean=1.989370, std=3.136040\n",
      "2025-05-10 17:00:14 - INFO -   returns: mean=0.004723, std=0.076010\n",
      "2025-05-10 17:00:14 - INFO -   item_price: mean=774.551270, std=1501.893677\n",
      "2025-05-10 17:00:14 - INFO -   lag_sales_1: mean=1.650155, std=3.208797\n",
      "2025-05-10 17:00:14 - INFO -   lag_sales_2: mean=1.385016, std=3.188548\n",
      "2025-05-10 17:00:14 - INFO -   lag_sales_3: mean=1.172488, std=3.130180\n",
      "2025-05-10 17:00:14 - INFO -   lag_returns_1: mean=0.003681, std=0.068064\n",
      "2025-05-10 17:00:14 - INFO -   lag_returns_2: mean=0.002879, std=0.061564\n",
      "2025-05-10 17:00:14 - INFO -   lag_returns_3: mean=0.002328, std=0.053651\n",
      "2025-05-10 17:00:14 - INFO -   lag_price_1: mean=575.332397, std=1276.040405\n",
      "2025-05-10 17:00:14 - INFO -   lag_price_2: mean=438.983551, std=1101.539551\n",
      "2025-05-10 17:00:14 - INFO -   lag_price_3: mean=340.796783, std=958.164185\n",
      "2025-05-10 17:00:15 - INFO - Scaler center: [  1.   0. 379.   1.   1.   0.   0.   0.   0. 299. 149.   0.]\n",
      "2025-05-10 17:00:15 - INFO - Scaler scale: [  1.          1.        650.          2.          2.          1.\n",
      "   1.          1.          1.        599.        434.        320.7749939]\n",
      "2025-05-10 17:00:15 - INFO - Post-scaling numerical means:\n",
      "2025-05-10 17:00:15 - INFO -   item_cnt_day_winsor: mean=0.980713, std=3.110482\n",
      "2025-05-10 17:00:15 - INFO -   returns: mean=0.004689, std=0.075404\n",
      "2025-05-10 17:00:15 - INFO -   item_price: mean=0.633670, std=2.387086\n",
      "2025-05-10 17:00:15 - INFO -   lag_sales_1: mean=0.323241, std=1.588679\n",
      "2025-05-10 17:00:15 - INFO -   lag_sales_2: mean=0.193552, std=1.578053\n",
      "2025-05-10 17:00:15 - INFO -   lag_sales_3: mean=1.181345, std=3.110323\n",
      "2025-05-10 17:00:15 - INFO -   lag_returns_1: mean=0.003672, std=0.068046\n",
      "2025-05-10 17:00:15 - INFO -   lag_returns_2: mean=0.002891, std=0.061297\n",
      "2025-05-10 17:00:15 - INFO -   lag_returns_3: mean=0.002360, std=0.053955\n",
      "2025-05-10 17:00:15 - INFO -   lag_price_1: mean=0.482933, std=2.168161\n",
      "2025-05-10 17:00:15 - INFO -   lag_price_2: mean=0.698105, std=2.563072\n",
      "2025-05-10 17:00:15 - INFO -   lag_price_3: mean=1.105998, std=3.024879\n",
      "2025-05-10 17:00:15 - INFO - Robust scaling time: 1.23 seconds\n",
      "2025-05-10 17:00:15 - INFO - Features after preprocessing: 17\n",
      "2025-05-10 17:00:15 - INFO - Final column selection and dtype optimization time: 0.09 seconds\n",
      "2025-05-10 17:00:15 - INFO - Total preprocessing time: 26.45 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler('/workspace/processed_data/preprocess.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Early column dropping\n",
    "    keep_cols = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_category_id', 'item_cnt_day', 'item_price']\n",
    "    data = data[keep_cols]\n",
    "    logger.info(f\"Initial columns kept: {data.columns.tolist()}\")\n",
    "    \n",
    "    # Optimize dtypes early\n",
    "    data = data.astype({\n",
    "        'date_block_num': 'int16',\n",
    "        'shop_id': 'int32',\n",
    "        'item_id': 'int32',\n",
    "        'item_category_id': 'int32',\n",
    "        'item_cnt_day': 'float32',\n",
    "        'item_price': 'float32'\n",
    "    }, errors='ignore')\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    step_time = time.time()\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%d.%m.%Y', errors='coerce')\n",
    "    data = data[data['date'].notna()]\n",
    "    logger.info(f\"Records after removing invalid dates: {len(data)}\")\n",
    "    logger.info(f\"Date conversion time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    step_time = time.time()\n",
    "    logger.info(f\"Duplicate records: {data.duplicated().sum()}\")\n",
    "    data = data.drop_duplicates()\n",
    "    logger.info(f\"Duplicate removal time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Verify no missing values\n",
    "    step_time = time.time()\n",
    "    logger.info(\"\\nMissing values before processing:\")\n",
    "    logger.info(data[['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'item_cnt_day', 'item_category_id']].isna().sum().to_string())\n",
    "    if data[['item_cnt_day', 'item_price']].isna().any().any():\n",
    "        raise ValueError(\"Unexpected missing values in item_cnt_day or item_price.\")\n",
    "    logger.info(f\"Missing value check time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Winsorization\n",
    "    def winsorize_sales_chunk(chunk):\n",
    "        chunk = chunk.sort_values(['shop_id', 'item_id', 'date'])\n",
    "        rolling_stats = chunk.groupby(['shop_id', 'item_id'])['item_cnt_day'].rolling(window=30, min_periods=1).agg(['mean', 'std']).reset_index()\n",
    "        rolling_stats['upper_bound'] = rolling_stats['mean'] + 3 * rolling_stats['std']\n",
    "        rolling_stats['upper_bound'] = rolling_stats['upper_bound'].fillna(chunk['item_cnt_day'].quantile(0.99))\n",
    "        \n",
    "        chunk = chunk.merge(rolling_stats[['upper_bound']], left_index=True, right_index=True)\n",
    "        chunk['item_cnt_day_winsor'] = np.minimum(chunk['item_cnt_day'], chunk['upper_bound'])\n",
    "        chunk['is_outlier'] = chunk['item_cnt_day'] > chunk['upper_bound']\n",
    "        return chunk\n",
    "    \n",
    "    step_time = time.time()\n",
    "    chunk_size = 500000\n",
    "    try:\n",
    "        data = winsorize_sales_chunk(data)\n",
    "    except MemoryError:\n",
    "        logger.info(\"MemoryError during Winsorization. Using chunked processing...\")\n",
    "        chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "        data = pd.concat([winsorize_sales_chunk(chunk) for chunk in chunks], ignore_index=True)\n",
    "    outlier_count = data['is_outlier'].sum()\n",
    "    logger.info(f\"Outliers detected: {outlier_count} ({(outlier_count / len(data) * 100):.2f}%)\")\n",
    "    data = data.drop(columns=['is_outlier', 'upper_bound'])\n",
    "    logger.info(f\"Winsorization time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Handle negative sales\n",
    "    step_time = time.time()\n",
    "    data['returns'] = data['item_cnt_day_winsor'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "    data['item_cnt_day_winsor'] = data['item_cnt_day_winsor'].apply(lambda x: max(0, x))\n",
    "    logger.info(f\"Negative sales after processing: {(data['item_cnt_day_winsor'] < 0).sum()}\")\n",
    "    logger.info(f\"Negative sales handling time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Aggregate to monthly level\n",
    "    step_time = time.time()\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    monthly_sales = data.groupby([\n",
    "        'year', 'month', 'shop_id', 'item_id', 'item_category_id', 'date_block_num'\n",
    "    ], sort=False).agg({\n",
    "        'item_cnt_day_winsor': 'sum',\n",
    "        'returns': 'sum',\n",
    "        'item_price': 'mean'\n",
    "    }).reset_index()\n",
    "    monthly_sales['date'] = pd.to_datetime(monthly_sales[['year', 'month']].assign(day=1))\n",
    "    logger.info(f\"Monthly sales shape: {monthly_sales.shape}\")\n",
    "    logger.info(f\"Aggregation time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Create lag features\n",
    "    def create_lag_features(df):\n",
    "        df = df.sort_values(['shop_id', 'item_id', 'date'])\n",
    "        for lag in [1, 2, 3]:\n",
    "            df[f'lag_sales_{lag}'] = df.groupby(['shop_id', 'item_id'], sort=False)['item_cnt_day_winsor'].shift(lag)\n",
    "            df[f'lag_returns_{lag}'] = df.groupby(['shop_id', 'item_id'], sort=False)['returns'].shift(lag)\n",
    "            df[f'lag_price_{lag}'] = df.groupby(['shop_id', 'item_id'], sort=False)['item_price'].shift(lag)\n",
    "        return df\n",
    "    \n",
    "    step_time = time.time()\n",
    "    try:\n",
    "        monthly_sales = create_lag_features(monthly_sales)\n",
    "    except MemoryError:\n",
    "        logger.info(\"MemoryError during lag feature creation. Using chunked processing...\")\n",
    "        chunks = [monthly_sales[i:i + chunk_size] for i in range(0, len(monthly_sales), chunk_size)]\n",
    "        monthly_sales = pd.concat([create_lag_features(chunk) for chunk in chunks], ignore_index=True)\n",
    "    \n",
    "    # Fill NA instead of dropping\n",
    "    numerical_cols = [\n",
    "        'item_cnt_day_winsor', 'returns', 'item_price',\n",
    "        'lag_sales_1', 'lag_sales_2', 'lag_sales_3',\n",
    "        'lag_returns_1', 'lag_returns_2', 'lag_returns_3',\n",
    "        'lag_price_1', 'lag_price_2', 'lag_price_3'\n",
    "    ]\n",
    "    monthly_sales[numerical_cols] = monthly_sales[numerical_cols].fillna(0)\n",
    "    logger.info(f\"Records after creating lag features and filling NA: {len(monthly_sales)}\")\n",
    "    logger.info(f\"Lag feature creation time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Save unscaled data for debugging\n",
    "    monthly_sales.to_parquet('/workspace/processed_data/monthly_sales_unscaled.parquet')\n",
    "    logger.info(\"Saved unscaled data to /workspace/processed_data/monthly_sales_unscaled.parquet\")\n",
    "    \n",
    "    # Robust scaling (fixed)\n",
    "    step_time = time.time()\n",
    "    scaler = RobustScaler()\n",
    "    try:\n",
    "        # Fit scaler on training data (date_block_num < 31)\n",
    "        train_data = monthly_sales[monthly_sales['date_block_num'] < 31][numerical_cols]\n",
    "        logger.info(f\"Training data shape for scaler fit: {train_data.shape}\")\n",
    "        logger.info(\"Pre-scaling training data stats:\")\n",
    "        for col in numerical_cols:\n",
    "            mean = train_data[col].mean()\n",
    "            std = train_data[col].std()\n",
    "            logger.info(f\"  {col}: mean={mean:.6f}, std={std:.6f}\")\n",
    "        scaler.fit(train_data)\n",
    "        logger.info(f\"Scaler center: {scaler.center_}\")\n",
    "        logger.info(f\"Scaler scale: {scaler.scale_}\")\n",
    "        # Apply to all data\n",
    "        scaled_data = scaler.transform(monthly_sales[numerical_cols])\n",
    "        monthly_sales.loc[:, numerical_cols] = scaled_data\n",
    "        # Verify scaling\n",
    "        logger.info(\"Post-scaling numerical means:\")\n",
    "        for col in numerical_cols:\n",
    "            mean = monthly_sales[col].mean()\n",
    "            std = monthly_sales[col].std()\n",
    "            logger.info(f\"  {col}: mean={mean:.6f}, std={std:.6f}\")\n",
    "        # Check for NaNs\n",
    "        if monthly_sales[numerical_cols].isna().any().any():\n",
    "            raise ValueError(\"NaN values introduced during scaling.\")\n",
    "        # Save scaler\n",
    "        with open('/workspace/processed_data/scaler.pkl', 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in scaling: {e}\")\n",
    "        raise\n",
    "    logger.info(f\"Robust scaling time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    step_time = time.time()\n",
    "    keep_cols = numerical_cols + ['shop_id', 'item_id', 'item_category_id', 'date', 'date_block_num']\n",
    "    monthly_sales = monthly_sales[keep_cols]\n",
    "    logger.info(f\"Features after preprocessing: {len(monthly_sales.columns)}\")\n",
    "    \n",
    "    # Check for duplicate columns\n",
    "    duplicate_cols = monthly_sales.columns[monthly_sales.columns.duplicated()].tolist()\n",
    "    if duplicate_cols:\n",
    "        logger.warning(f\"Duplicate columns found: {duplicate_cols}. Removing duplicates...\")\n",
    "        monthly_sales = monthly_sales.loc[:, ~monthly_sales.columns.duplicated()]\n",
    "        logger.info(f\"Features after removing duplicates: {len(monthly_sales.columns)}\")\n",
    "    \n",
    "    # Optimize final dtypes\n",
    "    monthly_sales = monthly_sales.astype({\n",
    "        'item_cnt_day_winsor': 'float32', 'returns': 'float32', 'item_price': 'float32',\n",
    "        'lag_sales_1': 'float32', 'lag_sales_2': 'float32', 'lag_sales_3': 'float32',\n",
    "        'lag_returns_1': 'float32', 'lag_returns_2': 'float32', 'lag_returns_3': 'float32',\n",
    "        'lag_price_1': 'float32', 'lag_price_2': 'float32', 'lag_price_3': 'float32',\n",
    "        'shop_id': 'int32', 'item_id': 'int32', 'item_category_id': 'int32',\n",
    "        'date_block_num': 'int16'\n",
    "    }, errors='ignore')\n",
    "    logger.info(f\"Final column selection and dtype optimization time: {time.time() - step_time:.2f} seconds\")\n",
    "    \n",
    "    logger.info(f\"Total preprocessing time: {time.time() - start_time:.2f} seconds\")\n",
    "    return monthly_sales\n",
    "\n",
    "# Preprocess data\n",
    "monthly_sales = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f9a7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "monthly_totals = monthly_sales.groupby('date')['item_cnt_day_winsor'].sum()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_totals.index, monthly_totals.values, marker='o')\n",
    "plt.title('Total Monthly Sales (After Aggregation)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Sales (Scaled)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20258ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 17:00:16 - INFO - Starting data splitting\n",
      "2025-05-10 17:00:16 - INFO - date_block_num distribution:\n",
      "2025-05-10 17:00:16 - INFO - date_block_num\n",
      "0     63224\n",
      "1     59935\n",
      "2     63977\n",
      "3     54638\n",
      "4     53296\n",
      "5     56196\n",
      "6     58035\n",
      "7     58022\n",
      "8     51575\n",
      "9     51090\n",
      "10    51460\n",
      "11    66276\n",
      "12    53320\n",
      "13    47704\n",
      "14    49291\n",
      "15    44740\n",
      "16    45766\n",
      "17    46481\n",
      "18    45756\n",
      "19    46439\n",
      "20    40423\n",
      "21    42595\n",
      "22    45755\n",
      "23    59275\n",
      "24    46775\n",
      "25    41390\n",
      "26    40464\n",
      "27    32875\n",
      "28    32220\n",
      "29    31909\n",
      "30    33527\n",
      "31    33486\n",
      "32    29678\n",
      "33    31529\n",
      "2025-05-10 17:00:16 - INFO - Shop-item overlap between train and val: 39403\n",
      "2025-05-10 17:00:16 - INFO - Shop-item overlap between train and test: 21116\n",
      "2025-05-10 17:00:16 - INFO - Training set size: 1514429 records\n",
      "2025-05-10 17:00:16 - INFO - Validation set size: 63164 records\n",
      "2025-05-10 17:00:16 - INFO - Test set size: 31529 records\n",
      "2025-05-10 17:00:16 - INFO - Training sales mean: 0.9894, std: 3.1360\n",
      "2025-05-10 17:00:16 - INFO - Validation sales mean: 0.8368, std: 2.7035\n",
      "2025-05-10 17:00:16 - INFO - Test sales mean: 0.8531, std: 2.5857\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler('/workspace/processed_data/split.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def split_data(data):\n",
    "    logger.info(\"Starting data splitting\")\n",
    "    \n",
    "    expected_cols = [\n",
    "        'item_cnt_day_winsor', 'returns', 'item_price',\n",
    "        'lag_sales_1', 'lag_sales_2', 'lag_sales_3',\n",
    "        'lag_returns_1', 'lag_returns_2', 'lag_returns_3',\n",
    "        'lag_price_1', 'lag_price_2', 'lag_price_3',\n",
    "        'shop_id', 'item_id', 'item_category_id', 'date', 'date_block_num'\n",
    "    ]\n",
    "    missing_cols = [col for col in expected_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        logger.error(f\"Missing columns in data: {missing_cols}\")\n",
    "        raise ValueError(f\"Missing columns in data: {missing_cols}\")\n",
    "    \n",
    "    date_block_counts = data['date_block_num'].value_counts().sort_index()\n",
    "    logger.info(\"date_block_num distribution:\")\n",
    "    logger.info(date_block_counts.to_string())\n",
    "    \n",
    "    if not (data['date_block_num'] == 33).any():\n",
    "        logger.error(\"No data for date_block_num == 33 (October 2015).\")\n",
    "        raise ValueError(\"No data for date_block_num == 33 (October 2015).\")\n",
    "    \n",
    "    try:\n",
    "        train_data = data[data['date_block_num'] < 31]\n",
    "        val_data = data[(data['date_block_num'] >= 31) & (data['date_block_num'] <= 32)]\n",
    "        test_data = data[data['date_block_num'] == 33]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in splitting: {e}\")\n",
    "        raise\n",
    "    \n",
    "    train_pairs = train_data[['shop_id', 'item_id']].drop_duplicates()\n",
    "    val_pairs = val_data[['shop_id', 'item_id']].drop_duplicates()\n",
    "    test_pairs = test_data[['shop_id', 'item_id']].drop_duplicates()\n",
    "    overlap_train_val = train_pairs.merge(val_pairs, on=['shop_id', 'item_id'], how='inner').shape[0]\n",
    "    overlap_train_test = train_pairs.merge(test_pairs, on=['shop_id', 'item_id'], how='inner').shape[0]\n",
    "    logger.info(f\"Shop-item overlap between train and val: {overlap_train_val}\")\n",
    "    logger.info(f\"Shop-item overlap between train and test: {overlap_train_test}\")\n",
    "    \n",
    "    numerical_cols = [\n",
    "        'item_cnt_day_winsor', 'returns', 'item_price',\n",
    "        'lag_sales_1', 'lag_sales_2', 'lag_sales_3',\n",
    "        'lag_returns_1', 'lag_returns_2', 'lag_returns_3',\n",
    "        'lag_price_1', 'lag_price_2', 'lag_price_3'\n",
    "    ]\n",
    "    categorical_cols = ['shop_id', 'item_id', 'item_category_id']\n",
    "    feature_cols = numerical_cols + categorical_cols + ['date_block_num']\n",
    "    \n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['item_cnt_day_winsor']\n",
    "    X_val = val_data[feature_cols]\n",
    "    y_val = val_data['item_cnt_day_winsor']\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data['item_cnt_day_winsor']\n",
    "    \n",
    "    if not X_train.shape[0]:\n",
    "        logger.error(\"Training set is empty.\")\n",
    "        raise ValueError(\"Training set is empty.\")\n",
    "    if not X_val.shape[0]:\n",
    "        logger.error(\"Validation set is empty.\")\n",
    "        raise ValueError(\"Validation set is empty.\")\n",
    "    if not X_test.shape[0]:\n",
    "        logger.error(\"Test set is empty.\")\n",
    "        raise ValueError(\"Test set is empty.\")\n",
    "    \n",
    "    logger.info(f\"Training set size: {X_train.shape[0]} records\")\n",
    "    logger.info(f\"Validation set size: {X_val.shape[0]} records\")\n",
    "    logger.info(f\"Test set size: {X_test.shape[0]} records\")\n",
    "    logger.info(f\"Training sales mean: {y_train.mean():.4f}, std: {y_train.std():.4f}\")\n",
    "    logger.info(f\"Validation sales mean: {y_val.mean():.4f}, std: {y_val.std():.4f}\")\n",
    "    logger.info(f\"Test sales mean: {y_test.mean():.4f}, std: {y_test.std():.4f}\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Split data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(monthly_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6262864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 17:00:16 - INFO - Starting dataset saving\n",
      "2025-05-10 17:00:16 - INFO - Available disk space: 16.25 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 17:00:17 - INFO - Saved and verified X_train_processed.parquet at ./X_train_processed.parquet, size: 15.50 MB, permissions: 666\n",
      "2025-05-10 17:00:17 - INFO - Filesystem synced for X_train_processed.parquet\n",
      "2025-05-10 17:00:18 - INFO - Saved and verified y_train_processed.parquet at ./y_train_processed.parquet, size: 5.12 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO - Filesystem synced for y_train_processed.parquet\n",
      "2025-05-10 17:00:18 - INFO - Saved and verified X_val_processed.parquet at ./X_val_processed.parquet, size: 0.76 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO - Filesystem synced for X_val_processed.parquet\n",
      "2025-05-10 17:00:18 - INFO - Saved and verified y_val_processed.parquet at ./y_val_processed.parquet, size: 0.22 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO - Filesystem synced for y_val_processed.parquet\n",
      "2025-05-10 17:00:18 - INFO - Saved and verified X_test_processed.parquet at ./X_test_processed.parquet, size: 0.39 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO - Filesystem synced for X_test_processed.parquet\n",
      "2025-05-10 17:00:18 - INFO - Saved and verified y_test_processed.parquet at ./y_test_processed.parquet, size: 0.11 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO - Filesystem synced for y_test_processed.parquet\n",
      "2025-05-10 17:00:18 - INFO - Created dummy file ./.vscode_refresh_trigger to trigger VSCode refresh\n",
      "2025-05-10 17:00:18 - INFO - Listing files in output directory:\n",
      "2025-05-10 17:00:18 - INFO -   y_test_processed.parquet, size: 0.11 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO -   X_test_processed.parquet, size: 0.39 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO -   y_val_processed.parquet, size: 0.22 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO -   X_val_processed.parquet, size: 0.76 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO -   y_train_processed.parquet, size: 5.12 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO -   X_train_processed.parquet, size: 15.50 MB, permissions: 666\n",
      "2025-05-10 17:00:18 - INFO - Current workspace path: /workspace\n",
      "2025-05-10 17:00:18 - INFO - Ensure /workspace/processed_data is in VSCode's workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler('/workspace/processed_data/save.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def save_datasets(X_train, y_train, X_val, y_val, X_test, y_test, output_dir=\".\"):\n",
    "    logger.info(\"Starting dataset saving\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Check disk space\n",
    "    total, used, free = shutil.disk_usage('/')\n",
    "    free_gb = free / (2**30)\n",
    "    logger.info(f\"Available disk space: {free_gb:.2f} GiB\")\n",
    "    if free_gb < 5:\n",
    "        logger.error(\"Low disk space. Need >5 GiB.\")\n",
    "        raise ValueError(\"Low disk space. Need >5 GiB.\")\n",
    "    \n",
    "    def save_parquet(df, filename, chunk_size=100000):\n",
    "        try:\n",
    "            duplicate_cols = df.columns[df.columns.duplicated()].tolist()\n",
    "            if duplicate_cols:\n",
    "                logger.error(f\"Duplicate columns in {filename}: {duplicate_cols}\")\n",
    "                raise ValueError(f\"Duplicate columns in {filename}: {duplicate_cols}\")\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            table = pa.Table.from_pandas(df)\n",
    "            pq.write_table(table, filepath, compression='zstd', row_group_size=chunk_size)\n",
    "            # Verify file exists\n",
    "            if not os.path.exists(filepath):\n",
    "                logger.error(f\"Failed to save {filename}: File does not exist\")\n",
    "                raise OSError(f\"Failed to save {filename}: File does not exist\")\n",
    "            # Set permissions\n",
    "            os.chmod(filepath, 0o666)\n",
    "            # Verify row count\n",
    "            written = pd.read_parquet(filepath)\n",
    "            if written.shape[0] != df.shape[0]:\n",
    "                logger.error(f\"Row count mismatch in {filename}: expected {df.shape[0]}, got {written.shape[0]}\")\n",
    "                raise ValueError(f\"Row count mismatch in {filename}: expected {df.shape[0]}, got {written.shape[0]}\")\n",
    "            # Log file size and permissions\n",
    "            file_size = os.path.getsize(filepath) / (2**20)  # MB\n",
    "            permissions = oct(os.stat(filepath).st_mode)[-3:]\n",
    "            logger.info(f\"Saved and verified {filename} at {filepath}, size: {file_size:.2f} MB, permissions: {permissions}\")\n",
    "            # Force filesystem sync\n",
    "            subprocess.run(['sync'], check=True)\n",
    "            logger.info(f\"Filesystem synced for {filename}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving {filename}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    # Save datasets\n",
    "    save_parquet(X_train, 'X_train_processed.parquet')\n",
    "    save_parquet(y_train.to_frame(), 'y_train_processed.parquet')\n",
    "    save_parquet(X_val, 'X_val_processed.parquet')\n",
    "    save_parquet(y_val.to_frame(), 'y_val_processed.parquet')\n",
    "    save_parquet(X_test, 'X_test_processed.parquet')\n",
    "    save_parquet(y_test.to_frame(), 'y_test_processed.parquet')\n",
    "    \n",
    "    # Create dummy file to trigger VSCode refresh\n",
    "    dummy_file = os.path.join(output_dir, '.vscode_refresh_trigger')\n",
    "    with open(dummy_file, 'w') as f:\n",
    "        f.write('Trigger VSCode refresh')\n",
    "    os.chmod(dummy_file, 0o666)\n",
    "    logger.info(f\"Created dummy file {dummy_file} to trigger VSCode refresh\")\n",
    "    \n",
    "    # List files\n",
    "    logger.info(\"Listing files in output directory:\")\n",
    "    for f in os.listdir(output_dir):\n",
    "        if f.endswith('.parquet'):\n",
    "            file_path = os.path.join(output_dir, f)\n",
    "            file_size = os.path.getsize(file_path) / (2**20)  # MB\n",
    "            permissions = oct(os.stat(file_path).st_mode)[-3:]\n",
    "            logger.info(f\"  {f}, size: {file_size:.2f} MB, permissions: {permissions}\")\n",
    "    \n",
    "    # Verify workspace path\n",
    "    workspace_path = os.path.abspath('/workspace')\n",
    "    logger.info(f\"Current workspace path: {workspace_path}\")\n",
    "    logger.info(\"Ensure /workspace/processed_data is in VSCode's workspace\")\n",
    "    \n",
    "save_datasets(X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294e7109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 17:09:06 - INFO - Using GPU: NVIDIA RTX A6000\n",
      "2025-05-10 17:09:06 - INFO - ================================================================================\n",
      "2025-05-10 17:09:06 - INFO - Starting Hierarchical Attention LSTM Forecasting\n",
      "2025-05-10 17:09:06 - INFO - ================================================================================\n",
      "2025-05-10 17:09:06 - INFO - Python version: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "2025-05-10 17:09:06 - INFO - PyTorch version: 2.7.0+cu118\n",
      "2025-05-10 17:09:06 - INFO - CUDA available: True\n",
      "2025-05-10 17:09:06 - INFO - CUDA device: NVIDIA RTX A6000\n",
      "2025-05-10 17:09:06 - INFO - CUDA capability: (8, 6)\n",
      "2025-05-10 17:09:06 - INFO - CUDA memory: 44.45 GB\n",
      "2025-05-10 17:09:06 - INFO - Loading datasets...\n",
      "2025-05-10 17:09:06 - INFO - Loading dataset from /workspace/XAI-1/processed_data/X_train_processed.parquet and /workspace/XAI-1/processed_data/y_train_processed.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 17:09:06 - INFO - Loaded Parquet files in 0.26s\n",
      "2025-05-10 17:09:06 - INFO - Numerical feature stats:\n",
      "2025-05-10 17:09:06 - INFO -   item_cnt_day_winsor: mean=0.989370, std=3.136040\n",
      "2025-05-10 17:09:06 - INFO -   returns: mean=0.004723, std=0.076010\n",
      "2025-05-10 17:09:06 - INFO -   item_price: mean=0.608541, std=2.310606\n",
      "2025-05-10 17:09:06 - INFO -   lag_sales_1: mean=0.325077, std=1.604398\n",
      "2025-05-10 17:09:06 - INFO -   lag_sales_2: mean=0.192508, std=1.594274\n",
      "2025-05-10 17:09:06 - INFO -   lag_sales_3: mean=1.172488, std=3.130180\n",
      "2025-05-10 17:09:06 - INFO -   lag_returns_1: mean=0.003681, std=0.068064\n",
      "2025-05-10 17:09:06 - INFO -   lag_returns_2: mean=0.002879, std=0.061564\n",
      "2025-05-10 17:09:06 - INFO -   lag_returns_3: mean=0.002328, std=0.053651\n",
      "2025-05-10 17:09:06 - INFO -   lag_price_1: mean=0.461323, std=2.130285\n",
      "2025-05-10 17:09:06 - INFO -   lag_price_2: mean=0.668165, std=2.538110\n",
      "2025-05-10 17:09:07 - INFO -   lag_price_3: mean=1.062418, std=2.987029\n",
      "2025-05-10 17:09:07 - WARNING - item_cnt_day_winsor mean is 0.989370, expected ~0. Continuing...\n",
      "2025-05-10 17:09:07 - INFO - Max shop_id: 59, Max item_id: 22169, Max category_id: 83\n",
      "2025-05-10 17:09:07 - INFO - Precomputing groups for faster access...\n",
      "2025-05-10 17:09:08 - INFO - Saved group keys to /workspace/XAI-1/processed_data/X_train_processed_group_keys.pkl\n",
      "2025-05-10 17:09:08 - INFO - Number of shop-item groups: 406462\n",
      "2025-05-10 17:09:08 - INFO - Data loaded perfectly\n",
      "2025-05-10 17:09:08 - INFO - Loading dataset from /workspace/XAI-1/processed_data/X_val_processed.parquet and /workspace/XAI-1/processed_data/y_val_processed.parquet\n",
      "2025-05-10 17:09:08 - INFO - Loaded Parquet files in 0.04s\n",
      "2025-05-10 17:09:08 - INFO - Numerical feature stats:\n",
      "2025-05-10 17:09:08 - INFO -   item_cnt_day_winsor: mean=0.836846, std=2.703501\n",
      "2025-05-10 17:09:08 - INFO -   returns: mean=0.004164, std=0.065369\n",
      "2025-05-10 17:09:08 - INFO -   item_price: mean=0.944988, std=3.112585\n",
      "2025-05-10 17:09:08 - INFO -   lag_sales_1: mean=0.306048, std=1.302561\n",
      "2025-05-10 17:09:08 - INFO -   lag_sales_2: mean=0.220672, std=1.273677\n",
      "2025-05-10 17:09:08 - INFO -   lag_sales_3: mean=1.376550, std=2.831339\n",
      "2025-05-10 17:09:08 - INFO -   lag_returns_1: mean=0.003436, std=0.059850\n",
      "2025-05-10 17:09:08 - INFO -   lag_returns_2: mean=0.003261, std=0.059195\n",
      "2025-05-10 17:09:08 - INFO -   lag_returns_3: mean=0.003008, std=0.061825\n",
      "2025-05-10 17:09:08 - INFO -   lag_price_1: mean=0.836139, std=2.533882\n",
      "2025-05-10 17:09:08 - INFO -   lag_price_2: mean=1.243780, std=2.888572\n",
      "2025-05-10 17:09:08 - INFO -   lag_price_3: mean=1.891607, std=3.628916\n",
      "2025-05-10 17:09:08 - WARNING - item_cnt_day_winsor mean is 0.836846, expected ~0. Continuing...\n",
      "2025-05-10 17:09:08 - INFO - Max shop_id: 59, Max item_id: 22167, Max category_id: 83\n",
      "2025-05-10 17:09:08 - INFO - Precomputing groups for faster access...\n",
      "2025-05-10 17:09:09 - INFO - Saved group keys to /workspace/XAI-1/processed_data/X_val_processed_group_keys.pkl\n",
      "2025-05-10 17:09:09 - INFO - Number of shop-item groups: 49945\n",
      "2025-05-10 17:09:09 - INFO - Data loaded perfectly\n",
      "2025-05-10 17:09:09 - INFO - Loading dataset from /workspace/XAI-1/processed_data/X_test_processed.parquet and /workspace/XAI-1/processed_data/y_test_processed.parquet\n",
      "2025-05-10 17:09:09 - INFO - Loaded Parquet files in 0.02s\n",
      "2025-05-10 17:09:09 - INFO - Numerical feature stats:\n",
      "2025-05-10 17:09:09 - INFO -   item_cnt_day_winsor: mean=0.853088, std=2.585738\n",
      "2025-05-10 17:09:09 - INFO -   returns: mean=0.004060, std=0.064085\n",
      "2025-05-10 17:09:09 - INFO -   item_price: mean=1.217019, std=3.794487\n",
      "2025-05-10 17:09:09 - INFO -   lag_sales_1: mean=0.269500, std=1.329151\n",
      "2025-05-10 17:09:09 - INFO -   lag_sales_2: mean=0.189384, std=1.325182\n",
      "2025-05-10 17:09:09 - INFO -   lag_sales_3: mean=1.215723, std=2.638559\n",
      "2025-05-10 17:09:09 - INFO -   lag_returns_1: mean=0.003711, std=0.081334\n",
      "2025-05-10 17:09:09 - INFO -   lag_returns_2: mean=0.002696, std=0.051853\n",
      "2025-05-10 17:09:09 - INFO -   lag_returns_3: mean=0.002601, std=0.051551\n",
      "2025-05-10 17:09:09 - INFO -   lag_price_1: mean=0.813354, std=2.948715\n",
      "2025-05-10 17:09:09 - INFO -   lag_price_2: mean=1.043048, std=2.893565\n",
      "2025-05-10 17:09:09 - INFO -   lag_price_3: mean=1.625462, std=3.229757\n",
      "2025-05-10 17:09:09 - WARNING - item_cnt_day_winsor mean is 0.853088, expected ~0. Continuing...\n",
      "2025-05-10 17:09:09 - INFO - Max shop_id: 59, Max item_id: 22167, Max category_id: 83\n",
      "2025-05-10 17:09:09 - INFO - Precomputing groups for faster access...\n",
      "2025-05-10 17:09:09 - INFO - Saved group keys to /workspace/XAI-1/processed_data/X_test_processed_group_keys.pkl\n",
      "2025-05-10 17:09:09 - INFO - Number of shop-item groups: 31529\n",
      "2025-05-10 17:09:09 - INFO - Data loaded perfectly\n",
      "2025-05-10 17:09:09 - INFO - Dataset sizes - Train: 406462, Val: 49945, Test: 31529\n",
      "2025-05-10 17:09:09 - INFO - Creating model...\n",
      "2025-05-10 17:09:09 - INFO - Model parameters - Total: 2,628,319, Trainable: 2,628,319\n",
      "2025-05-10 17:09:09 - WARNING - TensorBoard not available, skipping logging\n",
      "2025-05-10 17:09:09 - INFO - No existing model found, starting training from scratch\n",
      "2025-05-10 17:09:09 - INFO - Starting model training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 969\u001b[0m\n\u001b[1;32m    966\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_properties(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtotal_memory\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    971\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in main execution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 851\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo existing model found, starting training from scratch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 851\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mlambda1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# Generate predictions\u001b[39;00m\n\u001b[1;32m    856\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 383\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, lr, lambda1, lambda2)\u001b[0m\n\u001b[1;32m    381\u001b[0m val_data_prefetched \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mstream(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mStream()):\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m    384\u001b[0m         val_data_prefetched\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    385\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerical\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumerical\u001b[39m\u001b[38;5;124m'\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m    386\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshop_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshop_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    390\u001b[0m         })\n\u001b[1;32m    392\u001b[0m epoch_pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 71\u001b[0m, in \u001b[0;36mPrefetchLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     loader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader)\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_batch\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m next_batch \u001b[38;5;129;01min\u001b[39;00m loader_iter:\n",
      "Cell \u001b[0;32mIn[9], line 93\u001b[0m, in \u001b[0;36mPrefetchLoader.preload\u001b[0;34m(self, loader_iter)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreload\u001b[39m(\u001b[38;5;28mself\u001b[39m, loader_iter):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/XAI-1/nvenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m/workspace/XAI-1/nvenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/XAI-1/nvenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1443\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1445\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/workspace/XAI-1/nvenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pyarrow.parquet as pq\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "import logging\n",
    "import pickle\n",
    "import subprocess\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler('./ha_lstm_forecasting.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# GPU Configuration - Added environment variables for performance tuning\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Disable launch blocking for better parallelization\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use first GPU\n",
    "os.environ['OMP_NUM_THREADS'] = '8'  # Control OpenMP threads\n",
    "os.environ['MKL_NUM_THREADS'] = '8'  # Control MKL threads\n",
    "\n",
    "# Set device to GPU with performance settings\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.benchmark = True  # Optimize for fixed input sizes\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Enable TensorFloat32\n",
    "    torch.backends.cudnn.allow_tf32 = True  # Enable TensorFloat32\n",
    "    logger.info(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    logger.info(\"Using CPU (no GPU available)\")\n",
    "\n",
    "# Add GPU memory state reporting function\n",
    "def report_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "        reserved = torch.cuda.memory_reserved() / (1024**3)\n",
    "        try:\n",
    "            smi_output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv']).decode()\n",
    "            gpu_util = int(smi_output.split('\\n')[1].replace(' %', ''))\n",
    "        except:\n",
    "            gpu_util = -1\n",
    "        return f\"GPU Memory: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB, Utilization={gpu_util}%\"\n",
    "    return \"No GPU available\"\n",
    "\n",
    "class PrefetchLoader:\n",
    "    \"\"\"\n",
    "    Prefetches data to GPU while model is training\n",
    "    \"\"\"\n",
    "    def __init__(self, loader):\n",
    "        self.loader = loader\n",
    "        self.stream = torch.cuda.Stream() if torch.cuda.is_available() else None\n",
    "    \n",
    "    def __iter__(self):\n",
    "        loader_iter = iter(self.loader)\n",
    "        self.preload(loader_iter)\n",
    "        batch = self.next_batch\n",
    "        \n",
    "        for next_batch in loader_iter:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            batch_on_device = {k: v.cuda(non_blocking=True) if isinstance(v, torch.Tensor) else v \n",
    "                              for k, v in batch.items()}\n",
    "            yield batch_on_device\n",
    "            batch = next_batch\n",
    "            self.preload(loader_iter)\n",
    "        \n",
    "        if batch is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            batch_on_device = {k: v.cuda(non_blocking=True) if isinstance(v, torch.Tensor) else v \n",
    "                              for k, v in batch.items()}\n",
    "            yield batch_on_device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def preload(self, loader_iter):\n",
    "        try:\n",
    "            self.next_batch = next(loader_iter)\n",
    "        except StopIteration:\n",
    "            self.next_batch = None\n",
    "            return\n",
    "        \n",
    "        if self.stream is not None:\n",
    "            with torch.cuda.stream(self.stream):\n",
    "                self.next_batch = {k: torch.from_numpy(v).pin_memory() if isinstance(v, np.ndarray) else v \n",
    "                                 for k, v in self.next_batch.items()}\n",
    "\n",
    "class SalesDataset(Dataset):\n",
    "    def __init__(self, X_file, y_file, sequence_length=12, num_shops=None, num_items=None, num_categories=None):\n",
    "        logger.info(f\"Loading dataset from {X_file} and {y_file}\")\n",
    "        start = time.time()\n",
    "        \n",
    "        # Verify file existence\n",
    "        if not os.path.exists(X_file) or not os.path.exists(y_file):\n",
    "            logger.error(f\"One or both files not found: {X_file}, {y_file}\")\n",
    "            raise FileNotFoundError(f\"One or both files not found: {X_file}, {y_file}\")\n",
    "        \n",
    "        # Load Parquet files more efficiently\n",
    "        self.X = pl.scan_parquet(X_file).collect()  # Lazily scan and then collect\n",
    "        self.y = pl.read_parquet(y_file).select(['item_cnt_day_winsor']).to_pandas()['item_cnt_day_winsor']\n",
    "        logger.info(f\"Loaded Parquet files in {time.time() - start:.2f}s\")\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_shops = num_shops\n",
    "        self.num_items = num_items\n",
    "        self.num_categories = num_categories\n",
    "        \n",
    "        self.numerical_cols = [\n",
    "            'item_cnt_day_winsor', 'returns', 'item_price',\n",
    "            'lag_sales_1', 'lag_sales_2', 'lag_sales_3',\n",
    "            'lag_returns_1', 'lag_returns_2', 'lag_returns_3',\n",
    "            'lag_price_1', 'lag_price_2', 'lag_price_3'\n",
    "        ]\n",
    "        self.categorical_cols = ['shop_id', 'item_id', 'item_category_id']\n",
    "        \n",
    "        # Validate data\n",
    "        X_numerical = self.X.select(self.numerical_cols).to_pandas()\n",
    "        if X_numerical.isna().any().any() or self.y.isna().any():\n",
    "            logger.error(\"NaN values detected in dataset\")\n",
    "            raise ValueError(\"NaN values in X or y\")\n",
    "        \n",
    "        logger.info(\"Numerical feature stats:\")\n",
    "        for col in self.numerical_cols:\n",
    "            mean = X_numerical[col].mean()\n",
    "            std = X_numerical[col].std()\n",
    "            logger.info(f\"  {col}: mean={mean:.6f}, std={std:.6f}\")\n",
    "        # Relax scaling check temporarily\n",
    "        if abs(X_numerical['item_cnt_day_winsor'].mean()) > 0.1:\n",
    "            logger.warning(f\"item_cnt_day_winsor mean is {X_numerical['item_cnt_day_winsor'].mean():.6f}, expected ~0. Continuing...\")\n",
    "        \n",
    "        # Validate indices\n",
    "        max_shop_id = self.X['shop_id'].max()\n",
    "        max_item_id = self.X['item_id'].max()\n",
    "        max_category_id = self.X['item_category_id'].max()\n",
    "        logger.info(f\"Max shop_id: {max_shop_id}, Max item_id: {max_item_id}, Max category_id: {max_category_id}\")\n",
    "        \n",
    "        if max_shop_id >= self.num_shops:\n",
    "            logger.warning(f\"shop_id {max_shop_id} exceeds num_shops {self.num_shops}. Capping indices.\")\n",
    "            self.X = self.X.with_columns(pl.col('shop_id').clip(upper=self.num_shops - 1))\n",
    "        if max_item_id >= self.num_items:\n",
    "            logger.warning(f\"item_id {max_item_id} exceeds num_items {self.num_items}. Capping indices.\")\n",
    "            self.X = self.X.with_columns(pl.col('item_id').clip(upper=self.num_items - 1))\n",
    "        if max_category_id >= self.num_categories:\n",
    "            logger.warning(f\"item_category_id {max_category_id} exceeds num_categories {self.num_categories}. Capping indices.\")\n",
    "            self.X = self.X.with_columns(pl.col('item_category_id').clip(upper=self.num_categories - 1))\n",
    "        \n",
    "        # Cache group keys\n",
    "        cache_file = X_file.replace('.parquet', '_group_keys.pkl')\n",
    "        if os.path.exists(cache_file):\n",
    "            logger.info(f\"Loading cached group keys from {cache_file}\")\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                self.group_keys = pickle.load(f)\n",
    "        else:\n",
    "            logger.info(\"Precomputing groups for faster access...\")\n",
    "            groups = self.X.group_by(['shop_id', 'item_id']).agg(pl.col('date_block_num'))\n",
    "            self.group_keys = [(row['shop_id'], row['item_id']) for row in groups.to_dicts()]\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(self.group_keys, f)\n",
    "            logger.info(f\"Saved group keys to {cache_file}\")\n",
    "        logger.info(f\"Number of shop-item groups: {len(self.group_keys)}\")\n",
    "        logger.info(\"Data loaded perfectly\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.group_keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        shop_id, item_id = self.group_keys[idx]\n",
    "        group = self.X.filter((pl.col('shop_id') == shop_id) & (pl.col('item_id') == item_id)).sort('date_block_num')\n",
    "        \n",
    "        if group['shop_id'].n_unique() > 1 or group['item_id'].n_unique() > 1:\n",
    "            raise ValueError(f\"Group {shop_id}, {item_id} has multiple shop_id or item_id values\")\n",
    "        if group['item_category_id'].n_unique() > 1:\n",
    "            logger.warning(f\"Group {shop_id}, {item_id} has multiple item_category_id values\")\n",
    "        \n",
    "        if len(group) < self.sequence_length:\n",
    "            pad_length = self.sequence_length - len(group)\n",
    "            numerical_pad = np.zeros((pad_length, len(self.numerical_cols)), dtype=np.float32)\n",
    "            categorical_pad = np.array([[shop_id, item_id, group['item_category_id'][0]]], dtype=np.int64).repeat(pad_length, axis=0)\n",
    "            date_block_pad = np.full((pad_length,), group['date_block_num'][0] - 1, dtype=np.int32)\n",
    "            \n",
    "            if pd.isna(categorical_pad[0, 2]):\n",
    "                raise ValueError(f\"Invalid item_category_id in group {shop_id}, {item_id}\")\n",
    "            \n",
    "            numerical = np.concatenate([numerical_pad, group.select(self.numerical_cols).to_pandas().values], axis=0).astype(np.float32)\n",
    "            shop_ids = np.concatenate([categorical_pad[:, 0], group['shop_id'].to_numpy()], axis=0).astype(np.int64)\n",
    "            item_ids = np.concatenate([categorical_pad[:, 1], group['item_id'].to_numpy()], axis=0).astype(np.int64)\n",
    "            category_ids = np.concatenate([categorical_pad[:, 2], group['item_category_id'].to_numpy()], axis=0).astype(np.int64)\n",
    "            date_block_num = np.concatenate([date_block_pad, group['date_block_num'].to_numpy()], axis=0).astype(np.int32)\n",
    "        else:\n",
    "            numerical = group.select(self.numerical_cols).to_pandas().values[-self.sequence_length:].astype(np.float32)\n",
    "            shop_ids = group['shop_id'].to_numpy()[-self.sequence_length:].astype(np.int64)\n",
    "            item_ids = group['item_id'].to_numpy()[-self.sequence_length:].astype(np.int64)\n",
    "            category_ids = group['item_category_id'].to_numpy()[-self.sequence_length:].astype(np.int64)\n",
    "            date_block_num = group['date_block_num'].to_numpy()[-self.sequence_length:].astype(np.int32)\n",
    "        \n",
    "        target = self.y.loc[group['index'][-1]].astype(np.float32) if 'index' in group.columns else self.y.iloc[group.index[-1]].astype(np.float32)\n",
    "        \n",
    "        if shop_ids.max() >= self.num_shops or item_ids.max() >= self.num_items or category_ids.max() >= self.num_categories:\n",
    "            raise ValueError(f\"Invalid indices in group {shop_id}, {item_id}\")\n",
    "        \n",
    "        return {\n",
    "            'numerical': numerical,\n",
    "            'shop_ids': shop_ids,\n",
    "            'item_ids': item_ids,\n",
    "            'category_ids': category_ids,\n",
    "            'target': target,\n",
    "            'date_block_num': date_block_num[-1],\n",
    "            'identifiers': np.array([shop_id, item_id, date_block_num[-1]], dtype=np.int32)\n",
    "        }\n",
    "\n",
    "class FeatureAttention(nn.Module):\n",
    "    def __init__(self, feature_dim, attention_dim=64):\n",
    "        super(FeatureAttention, self).__init__()\n",
    "        self.query = nn.Linear(feature_dim, attention_dim)\n",
    "        self.key = nn.Linear(feature_dim, attention_dim)\n",
    "        self.value = nn.Linear(feature_dim, feature_dim)\n",
    "        self.scale = 1 / (attention_dim ** 0.5)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        nn.init.xavier_uniform_(self.query.weight)\n",
    "        nn.init.xavier_uniform_(self.key.weight)\n",
    "        nn.init.xavier_uniform_(self.value.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "        scores = torch.bmm(query, key.transpose(1, 2)) * self.scale\n",
    "        weights = self.softmax(scores)\n",
    "        output = torch.bmm(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "class HALSTM(nn.Module):\n",
    "    def __init__(self, num_shops, num_items, num_categories, embed_dim=16, numerical_dim=12, \n",
    "                 hidden_dim=128, num_layers=2, num_heads=4, dropout=0.1, forecast_horizon=1):\n",
    "        super(HALSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.shop_embed = nn.Embedding(num_shops, embed_dim)\n",
    "        self.item_embed = nn.Embedding(num_items, embed_dim)\n",
    "        self.category_embed = nn.Embedding(num_categories, embed_dim)\n",
    "        # Use better initialization for embeddings\n",
    "        nn.init.normal_(self.shop_embed.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.item_embed.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.category_embed.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        self.input_dim = embed_dim * 3 + numerical_dim\n",
    "        self.feature_attention = FeatureAttention(self.input_dim)\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.mha = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.gate = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc_shared = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_horizons = nn.ModuleList([nn.Linear(hidden_dim, 1) for _ in range(forecast_horizon)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initialize weights properly for better training\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, numerical, shop_ids, item_ids, category_ids):\n",
    "        # More efficient GPU memory usage with contiguous tensors\n",
    "        batch_size, seq_len, _ = numerical.size()\n",
    "        shop_embed = self.shop_embed(shop_ids)\n",
    "        item_embed = self.item_embed(item_ids)\n",
    "        category_embed = self.category_embed(category_ids)\n",
    "        \n",
    "        # Create a contiguous tensor for better GPU utilization\n",
    "        x = torch.cat([numerical, shop_embed, item_embed, category_embed], dim=-1).contiguous()\n",
    "        x, feature_weights = self.feature_attention(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Optimize LSTM computation\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=x.device, dtype=x.dtype).contiguous()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=x.device, dtype=x.dtype).contiguous()\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Multi-head attention with optimized memory access\n",
    "        mha_out, mha_weights = self.mha(lstm_out, lstm_out, lstm_out)\n",
    "        mha_out = self.dropout(mha_out)\n",
    "        \n",
    "        # Use the last sequence outputs\n",
    "        combined = torch.cat([lstm_out[:, -1, :], mha_out[:, -1, :]], dim=-1)\n",
    "        gate = self.sigmoid(self.gate(combined))\n",
    "        fused = gate * lstm_out[:, -1, :] + (1 - gate) * mha_out[:, -1, :]\n",
    "        \n",
    "        # Final prediction layers\n",
    "        shared = self.relu(self.fc_shared(fused))\n",
    "        outputs = torch.cat([fc(shared).unsqueeze(1) for fc in self.fc_horizons], dim=1)\n",
    "        \n",
    "        return outputs.squeeze(-1), {\n",
    "            'feature_weights': feature_weights,\n",
    "            'mha_weights': mha_weights,\n",
    "            'fused_output': fused,\n",
    "            'gate_weights': gate\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # More efficient collation that pre-allocates arrays\n",
    "    batch_size = len(batch)\n",
    "    seq_len = len(batch[0]['numerical'])\n",
    "    num_features = batch[0]['numerical'].shape[1]\n",
    "    \n",
    "    # Pre-allocate arrays\n",
    "    numerical = np.zeros((batch_size, seq_len, num_features), dtype=np.float32)\n",
    "    shop_ids = np.zeros((batch_size, seq_len), dtype=np.int64)\n",
    "    item_ids = np.zeros((batch_size, seq_len), dtype=np.int64)\n",
    "    category_ids = np.zeros((batch_size, seq_len), dtype=np.int64)\n",
    "    target = np.zeros(batch_size, dtype=np.float32)\n",
    "    date_block_num = np.zeros(batch_size, dtype=np.int32)\n",
    "    identifiers = np.zeros((batch_size, 3), dtype=np.int32)\n",
    "    \n",
    "    # Fill arrays\n",
    "    for i, item in enumerate(batch):\n",
    "        numerical[i] = item['numerical']\n",
    "        shop_ids[i] = item['shop_ids']\n",
    "        item_ids[i] = item['item_ids']\n",
    "        category_ids[i] = item['category_ids']\n",
    "        target[i] = item['target']\n",
    "        date_block_num[i] = item['date_block_num']\n",
    "        identifiers[i] = item['identifiers']\n",
    "    \n",
    "    return {\n",
    "        'numerical': numerical,\n",
    "        'shop_ids': shop_ids,\n",
    "        'item_ids': item_ids,\n",
    "        'category_ids': category_ids,\n",
    "        'target': target,\n",
    "        'date_block_num': date_block_num,\n",
    "        'identifiers': identifiers\n",
    "    }\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50, lr=0.001, lambda1=0.01, lambda2=0.01):\n",
    "    logger.info(\"Starting model training\")\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    \n",
    "    # Use mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "    \n",
    "    # Use optimized optimizer with weight decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01, eps=1e-7)\n",
    "    \n",
    "    # Learning rate scheduler with warmup\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=lr, \n",
    "        epochs=num_epochs, steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1  # 10% warmup\n",
    "    )\n",
    "    \n",
    "    # Tracking buffers\n",
    "    interpret_buffers = {\n",
    "        'sample_id': [], 'shop_id': [], 'item_id': [], 'date_block_num': [],\n",
    "        'feature_weights': [], 'mha_weights': [], 'fused_output': [], 'gate_weights': []\n",
    "    }\n",
    "    best_val_loss = float('inf')\n",
    "    output_dir = '/workspace/XAI-1/processed_data'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Pre-fetch validation data to GPU to speed up validation\n",
    "    val_data_prefetched = []\n",
    "    with torch.cuda.stream(torch.cuda.Stream()):\n",
    "        for batch in val_loader:\n",
    "            val_data_prefetched.append({\n",
    "                'numerical': torch.tensor(batch['numerical'], device=device, dtype=torch.float32),\n",
    "                'shop_ids': torch.tensor(batch['shop_ids'], device=device, dtype=torch.long),\n",
    "                'item_ids': torch.tensor(batch['item_ids'], device=device, dtype=torch.long),\n",
    "                'category_ids': torch.tensor(batch['category_ids'], device=device, dtype=torch.long),\n",
    "                'target': torch.tensor(batch['target'], device=device, dtype=torch.float32)\n",
    "            })\n",
    "    \n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\")\n",
    "    for epoch in epoch_pbar:\n",
    "        # Clear buffer to save memory\n",
    "        for k in interpret_buffers:\n",
    "            interpret_buffers[k] = []\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        batch_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", unit=\"batch\", leave=False)\n",
    "        for batch_idx, batch in enumerate(batch_pbar):\n",
    "            # Transfer batch to GPU (this is efficient with PrefetchLoader)\n",
    "            numerical = torch.tensor(batch['numerical'], device=device, dtype=torch.float32)\n",
    "            shop_ids = torch.tensor(batch['shop_ids'], device=device, dtype=torch.long)\n",
    "            item_ids = torch.tensor(batch['item_ids'], device=device, dtype=torch.long)\n",
    "            category_ids = torch.tensor(batch['category_ids'], device=device, dtype=torch.long)\n",
    "            target = torch.tensor(batch['target'], device=device, dtype=torch.float32)\n",
    "            \n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad(set_to_none=True)  # More efficient than .zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output, interpret_data = model(numerical, shop_ids, item_ids, category_ids)\n",
    "                mse_loss = criterion(output[:, -1], target)\n",
    "                att_reg = lambda1 * torch.mean(torch.sum(interpret_data['feature_weights'] ** 2, dim=-1))\n",
    "                temp_reg = lambda2 * torch.mean((output[:, 1:] - output[:, :-1]) ** 2) if output.shape[1] > 1 else 0\n",
    "                loss = mse_loss + att_reg + temp_reg\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Prevent exploding gradients\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()  # Update learning rate\n",
    "            \n",
    "            # Track metrics\n",
    "            train_loss += loss.item()\n",
    "            batch_pbar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{scheduler.get_last_lr()[0]:.6f}\")\n",
    "            \n",
    "            # Only collect interpretability data for a subset of batches to save memory\n",
    "            if batch_idx % 20 == 0:\n",
    "                gpu_info = report_gpu_memory()\n",
    "                logger.debug(f\"Batch {batch_idx} processed, {gpu_info}\")\n",
    "                \n",
    "                # Store interpretability data\n",
    "                sample_ids = [str(uuid4()) for _ in range(numerical.size(0))]\n",
    "                interpret_buffers['sample_id'].extend(sample_ids)\n",
    "                interpret_buffers['shop_id'].extend(batch['identifiers'][:, 0])\n",
    "                interpret_buffers['item_id'].extend(batch['identifiers'][:, 1])\n",
    "                interpret_buffers['date_block_num'].extend(batch['identifiers'][:, 2])\n",
    "                \n",
    "                # Store as CPU tensors to save GPU memory\n",
    "                interpret_buffers['feature_weights'].append(interpret_data['feature_weights'].detach().cpu().numpy())\n",
    "                interpret_buffers['mha_weights'].append(interpret_data['mha_weights'].detach().cpu().numpy())\n",
    "                interpret_buffers['fused_output'].append(interpret_data['fused_output'].detach().cpu().numpy())\n",
    "                interpret_buffers['gate_weights'].append(interpret_data['gate_weights'].detach().cpu().numpy())\n",
    "                \n",
    "                # Force garbage collection on GPU\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_data_prefetched:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output, _ = model(batch['numerical'], batch['shop_ids'], \n",
    "                                     batch['item_ids'], batch['category_ids'])\n",
    "                    loss = criterion(output[:, -1], batch['target'])\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_data_prefetched)\n",
    "        \n",
    "        # Log statistics\n",
    "        epoch_time = time.time() - start_time\n",
    "        eta_str = f\"{int(epoch_time * (num_epochs - epoch - 1) // 3600)}h {int((epoch_time * (num_epochs - epoch - 1) % 3600) // 60)}m\"\n",
    "        gpu_info = report_gpu_memory()\n",
    "        \n",
    "        epoch_pbar.set_postfix({\n",
    "            'train_loss': f\"{train_loss:.4f}\",\n",
    "            'val_loss': f\"{val_loss:.4f}\",\n",
    "            'eta': eta_str\n",
    "        })\n",
    "        logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                   f\"{gpu_info}, ETA: {eta_str}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            logger.info(f\"New best validation loss: {best_val_loss:.4f} - Saving model\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, os.path.join(output_dir, 'best_ha_lstm.pth'))\n",
    "        \n",
    "        # Save interpretability data periodically\n",
    "        if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n",
    "            logger.info(\"Saving interpretability outputs\")\n",
    "            \n",
    "            # Concatenate collected data\n",
    "            if interpret_buffers['feature_weights']:\n",
    "                feature_weights = np.concatenate(interpret_buffers['feature_weights'], axis=0)\n",
    "                mha_weights = np.concatenate(interpret_buffers['mha_weights'], axis=0)\n",
    "                fused_output = np.concatenate(interpret_buffers['fused_output'], axis=0)\n",
    "                gate_weights = np.concatenate(interpret_buffers['gate_weights'], axis=0)\n",
    "                \n",
    "                interpret_df = pd.DataFrame({\n",
    "                    'sample_id': interpret_buffers['sample_id'],\n",
    "                    'shop_id': interpret_buffers['shop_id'],\n",
    "                    'item_id': interpret_buffers['item_id'],\n",
    "                    'date_block_num': interpret_buffers['date_block_num']\n",
    "                })\n",
    "                \n",
    "                epoch_dir = os.path.join(output_dir, f'epoch_{epoch+1}')\n",
    "                os.makedirs(epoch_dir, exist_ok=True)\n",
    "                \n",
    "                # Save interpretability data\n",
    "                interpret_df.to_csv(os.path.join(epoch_dir, 'interpret_indices.csv'), index=False)\n",
    "                np.save(os.path.join(epoch_dir, 'feature_weights.npy'), feature_weights)\n",
    "                np.save(os.path.join(epoch_dir, 'mha_weights.npy'), mha_weights)\n",
    "                \n",
    "                fused_cols = [f'fused_dim_{i}' for i in range(fused_output.shape[1])]\n",
    "                fused_df = pd.DataFrame(fused_output, columns=fused_cols)\n",
    "                fused_df = pd.concat([interpret_df.reset_index(drop=True), fused_df], axis=1)\n",
    "                fused_df.to_csv(os.path.join(epoch_dir, 'fused_output.csv'), index=False)\n",
    "                \n",
    "                gate_df = pd.DataFrame(gate_weights, columns=[f'gate_dim_{i}' for i in range(gate_weights.shape[1])])\n",
    "                gate_df = pd.concat([interpret_df.reset_index(drop=True), gate_df], axis=1)\n",
    "                gate_df.to_csv(os.path.join(epoch_dir, 'gate_weights.csv'), index=False)\n",
    "                \n",
    "                logger.info(f\"Saved interpretability data to {epoch_dir}\")\n",
    "        \n",
    "        # Clear memory after each epoch\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    logger.info(f\"Training completed. Best validation loss: {best_val_loss:.6f}\")\n",
    "    return model\n",
    "\n",
    "def predict(model, test_loader):\n",
    "    logger.info(\"Starting prediction\")\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    identifiers = []\n",
    "    \n",
    "    # Use CUDA events for accurate timing\n",
    "    if torch.cuda.is_available():\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Predicting\", unit=\"batch\"):\n",
    "            numerical = torch.tensor(batch['numerical'], device=device, dtype=torch.float32)\n",
    "            shop_ids = torch.tensor(batch['shop_ids'], device=device, dtype=torch.long)\n",
    "            item_ids = torch.tensor(batch['item_ids'], device=device, dtype=torch.long)\n",
    "            category_ids = torch.tensor(batch['category_ids'], device=device, dtype=torch.long)\n",
    "            \n",
    "            # Use CUDA streams for parallel execution\n",
    "            with torch.cuda.stream(torch.cuda.Stream()):\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output, _ = model(numerical, shop_ids, item_ids, category_ids)\n",
    "                    preds = output.detach().cpu().numpy()\n",
    "            \n",
    "            predictions.append(preds)\n",
    "            identifiers.append(batch['identifiers'])\n",
    "    \n",
    "    # Measure prediction time\n",
    "    if torch.cuda.is_available():\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        predict_time = start_event.elapsed_time(end_event) / 1000  # convert to seconds\n",
    "    else:\n",
    "        predict_time = time.time() - start_time\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    identifiers = np.concatenate(identifiers, axis=0)\n",
    "    \n",
    "    logger.info(f\"Prediction completed in {predict_time:.2f}s for {len(predictions)} samples\")\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['shop_id'] = identifiers[:, 0]\n",
    "    pred_df['item_id'] = identifiers[:, 1]\n",
    "    pred_df['date_block_num'] = identifiers[:, 2]\n",
    "    \n",
    "    # Add predictions for all forecast horizons\n",
    "    for h in range(predictions.shape[1]):\n",
    "        pred_df[f'forecast_h{h+1}'] = predictions[:, h]\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "def visualize_results(pred_df, true_df=None, output_dir='/workspace/XAI-1/results'):\n",
    "    \"\"\"\n",
    "    Visualize prediction results and generate analysis plots\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    logger.info(f\"Generating visualizations in {output_dir}\")\n",
    "    \n",
    "    # Set style for better plots\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    sns.set_context(\"paper\", font_scale=1.5)\n",
    "    \n",
    "    # Plot 1: Distribution of predictions\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for h in range(1, len([col for col in pred_df.columns if 'forecast' in col]) + 1):\n",
    "        sns.kdeplot(pred_df[f'forecast_h{h}'], label=f'Horizon {h}')\n",
    "    plt.title('Distribution of Predictions Across Forecast Horizons')\n",
    "    plt.xlabel('Predicted Sales')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'prediction_distribution.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 2: Top shop-item combinations by forecast\n",
    "    top_items = pred_df.groupby(['shop_id', 'item_id'])['forecast_h1'].mean().sort_values(ascending=False).head(20)\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    top_items.plot(kind='bar')\n",
    "    plt.title('Top 20 Shop-Item Combinations by Forecast')\n",
    "    plt.xlabel('(Shop ID, Item ID)')\n",
    "    plt.ylabel('Average Forecast')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'top_shop_items.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot 3: Compare adjacent forecast horizons\n",
    "    if len([col for col in pred_df.columns if 'forecast' in col]) > 1:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        scatter = plt.scatter(\n",
    "            pred_df['forecast_h1'], \n",
    "            pred_df['forecast_h2'],\n",
    "            alpha=0.5,\n",
    "            c=pred_df['shop_id'] % 10,  # Color by shop_id modulo 10 for better visuals\n",
    "            cmap='tab10',\n",
    "            s=20\n",
    "        )\n",
    "        plt.title('Comparison of Adjacent Forecast Horizons')\n",
    "        plt.xlabel('Horizon 1 Forecast')\n",
    "        plt.ylabel('Horizon 2 Forecast')\n",
    "        plt.colorbar(scatter, label='Shop ID (mod 10)')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'horizon_comparison.png'), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # If we have true values, calculate and visualize errors\n",
    "    if true_df is not None:\n",
    "        # Merge predictions with true values\n",
    "        merged_df = pred_df.merge(true_df, on=['shop_id', 'item_id', 'date_block_num'], how='inner')\n",
    "        \n",
    "        # Calculate errors\n",
    "        merged_df['error'] = merged_df['forecast_h1'] - merged_df['item_cnt_day_winsor']\n",
    "        merged_df['abs_error'] = abs(merged_df['error'])\n",
    "        merged_df['squared_error'] = merged_df['error'] ** 2\n",
    "        \n",
    "        # Plot 4: Error distribution\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.histplot(merged_df['error'], kde=True, bins=50)\n",
    "        plt.title('Error Distribution')\n",
    "        plt.xlabel('Prediction Error (Predicted - True)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'error_distribution.png'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 5: Error by shop\n",
    "        shop_errors = merged_df.groupby('shop_id')['abs_error'].mean().sort_values(ascending=False)\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        shop_errors.plot(kind='bar')\n",
    "        plt.title('Mean Absolute Error by Shop')\n",
    "        plt.xlabel('Shop ID')\n",
    "        plt.ylabel('Mean Absolute Error')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'error_by_shop.png'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Return error metrics\n",
    "        mae = merged_df['abs_error'].mean()\n",
    "        rmse = np.sqrt(merged_df['squared_error'].mean())\n",
    "        logger.info(f\"Evaluation metrics - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "        return mae, rmse\n",
    "    \n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    # Set random seeds for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Configuration\n",
    "    data_dir = '/workspace/XAI-1/processed_data'\n",
    "    sequence_length = 12\n",
    "    batch_size = 2048  # Increased batch size for better GPU utilization\n",
    "    num_workers = 8\n",
    "    \n",
    "    # Metadata\n",
    "    num_shops = 60\n",
    "    num_items = 22171\n",
    "    num_categories = 84\n",
    "    \n",
    "    # Model parameters\n",
    "    embed_dim = 32  # Increased embedding dimension\n",
    "    hidden_dim = 256  # Increased hidden dimension for more capacity\n",
    "    num_layers = 3  # Deeper network\n",
    "    num_heads = 8  # More attention heads\n",
    "    dropout = 0.2\n",
    "    forecast_horizon = 3  # Predict multiple steps ahead\n",
    "    \n",
    "    # Training parameters\n",
    "    num_epochs = 50\n",
    "    lr = 0.002  # Slightly higher learning rate with OneCycleLR scheduler\n",
    "    lambda1 = 0.005  # Attention regularization\n",
    "    lambda2 = 0.01  # Temporal smoothness regularization\n",
    "    \n",
    "    # Load datasets with progress display\n",
    "    logger.info(\"Loading datasets...\")\n",
    "    \n",
    "    # Update file paths to match the actual files\n",
    "    # Train dataset\n",
    "    train_dataset = SalesDataset(\n",
    "        os.path.join(data_dir, 'X_train_processed.parquet'),\n",
    "        os.path.join(data_dir, 'y_train_processed.parquet'),\n",
    "        sequence_length=sequence_length,\n",
    "        num_shops=num_shops,\n",
    "        num_items=num_items,\n",
    "        num_categories=num_categories\n",
    "    )\n",
    "    \n",
    "    # Validation dataset\n",
    "    val_dataset = SalesDataset(\n",
    "        os.path.join(data_dir, 'X_val_processed.parquet'),\n",
    "        os.path.join(data_dir, 'y_val_processed.parquet'),\n",
    "        sequence_length=sequence_length,\n",
    "        num_shops=num_shops,\n",
    "        num_items=num_items,\n",
    "        num_categories=num_categories\n",
    "    )\n",
    "    \n",
    "    # Test dataset\n",
    "    test_dataset = SalesDataset(\n",
    "        os.path.join(data_dir, 'X_test_processed.parquet'),\n",
    "        os.path.join(data_dir, 'y_test_processed.parquet'),\n",
    "        sequence_length=sequence_length,\n",
    "        num_shops=num_shops,\n",
    "        num_items=num_items,\n",
    "        num_categories=num_categories\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "    \n",
    "    # Rest of the function remains the same...\n",
    "    \n",
    "    # Create data loaders with optimized memory usage\n",
    "    train_loader = PrefetchLoader(DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "        persistent_workers=True,\n",
    "        drop_last=True,  # Drop last batch for stable training\n",
    "        prefetch_factor=3  # Prefetch more batches\n",
    "    ))\n",
    "    \n",
    "    val_loader = PrefetchLoader(DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size * 2,  # Can use larger batch size for validation\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "        persistent_workers=True\n",
    "    ))\n",
    "    \n",
    "    test_loader = PrefetchLoader(DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size * 2,  # Can use larger batch size for testing\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "        persistent_workers=True\n",
    "    ))\n",
    "    \n",
    "    # Create and configure the model\n",
    "    logger.info(\"Creating model...\")\n",
    "    model = HALSTM(\n",
    "        num_shops=num_shops,\n",
    "        num_items=num_items,\n",
    "        num_categories=num_categories,\n",
    "        embed_dim=embed_dim,\n",
    "        numerical_dim=12,  # Number of numerical features\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        forecast_horizon=forecast_horizon\n",
    "    ).to(device)\n",
    "    \n",
    "    # Check model parameter count\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    logger.info(f\"Model parameters - Total: {total_params:,}, Trainable: {trainable_params:,}\")\n",
    "    \n",
    "    # Set up TensorBoard for monitoring\n",
    "    try:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        writer = SummaryWriter(log_dir=os.path.join(data_dir, 'logs', f'run_{time.strftime(\"%Y%m%d_%H%M%S\")}'))\n",
    "        logger.info(f\"TensorBoard logging enabled at {writer.log_dir}\")\n",
    "        # Log model graph\n",
    "        dummy_input = {\n",
    "            'numerical': torch.zeros(2, sequence_length, 12, device=device),\n",
    "            'shop_ids': torch.ones(2, sequence_length, dtype=torch.long, device=device),\n",
    "            'item_ids': torch.ones(2, sequence_length, dtype=torch.long, device=device),\n",
    "            'category_ids': torch.ones(2, sequence_length, dtype=torch.long, device=device)\n",
    "        }\n",
    "        writer.add_graph(model, (dummy_input['numerical'], \n",
    "                                dummy_input['shop_ids'], \n",
    "                                dummy_input['item_ids'], \n",
    "                                dummy_input['category_ids']))\n",
    "    except ImportError:\n",
    "        logger.warning(\"TensorBoard not available, skipping logging\")\n",
    "        writer = None\n",
    "    \n",
    "    # Check if model checkpoint exists\n",
    "    model_path = os.path.join(data_dir, 'best_ha_lstm.pth')\n",
    "    if os.path.exists(model_path):\n",
    "        logger.info(f\"Loading existing model from {model_path}\")\n",
    "        checkpoint = torch.load(model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Ask user if they want to continue training\n",
    "        user_input = input(\"Resume training? (y/n): \")\n",
    "        if user_input.lower() == 'y':\n",
    "            logger.info(\"Resuming training...\")\n",
    "            model = train_model(model, train_loader, val_loader, \n",
    "                               num_epochs=num_epochs, lr=lr, \n",
    "                               lambda1=lambda1, lambda2=lambda2)\n",
    "        else:\n",
    "            logger.info(\"Skipping training, using loaded model\")\n",
    "    else:\n",
    "        logger.info(\"No existing model found, starting training from scratch\")\n",
    "        model = train_model(model, train_loader, val_loader, \n",
    "                           num_epochs=num_epochs, lr=lr, \n",
    "                           lambda1=lambda1, lambda2=lambda2)\n",
    "    \n",
    "    # Generate predictions\n",
    "    logger.info(\"Generating predictions...\")\n",
    "    pred_df = predict(model, test_loader)\n",
    "    pred_df.to_csv(os.path.join(data_dir, 'predictions.csv'), index=False)\n",
    "    \n",
    "    # Load true values for evaluation\n",
    "    true_df = None\n",
    "    try:\n",
    "        true_df = pl.read_parquet(os.path.join(data_dir, 'test_y.parquet')).select(['shop_id', 'item_id', 'date_block_num', 'item_cnt_day_winsor']).to_pandas()\n",
    "        logger.info(\"Loaded true values for evaluation\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not load true values: {e}\")\n",
    "    \n",
    "    # Visualize results\n",
    "    metrics = visualize_results(pred_df, true_df)\n",
    "    if metrics:\n",
    "        mae, rmse = metrics\n",
    "        if writer:\n",
    "            writer.add_hparams(\n",
    "                {\n",
    "                    'embed_dim': embed_dim,\n",
    "                    'hidden_dim': hidden_dim,\n",
    "                    'num_layers': num_layers,\n",
    "                    'num_heads': num_heads,\n",
    "                    'dropout': dropout,\n",
    "                    'lr': lr,\n",
    "                    'lambda1': lambda1,\n",
    "                    'lambda2': lambda2\n",
    "                },\n",
    "                {\n",
    "                    'mae': mae,\n",
    "                    'rmse': rmse,\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    # Export feature importance analysis\n",
    "    logger.info(\"Generating feature importance analysis...\")\n",
    "    try:\n",
    "        latest_epoch = max([int(d.split('_')[1]) for d in os.listdir(data_dir) if d.startswith('epoch_')])\n",
    "        latest_epoch_dir = os.path.join(data_dir, f'epoch_{latest_epoch}')\n",
    "        \n",
    "        # Load interpretability data\n",
    "        interpret_df = pd.read_csv(os.path.join(latest_epoch_dir, 'interpret_indices.csv'))\n",
    "        feature_weights = np.load(os.path.join(latest_epoch_dir, 'feature_weights.npy'))\n",
    "        \n",
    "        # Average feature weights across sequence dimension\n",
    "        avg_feature_weights = np.mean(feature_weights, axis=1)  # Average across sequence dimension\n",
    "        \n",
    "        # Create feature importance dataframe\n",
    "        feature_names = [\n",
    "            # Numerical features\n",
    "            'item_cnt_day_winsor', 'returns', 'item_price',\n",
    "            'lag_sales_1', 'lag_sales_2', 'lag_sales_3',\n",
    "            'lag_returns_1', 'lag_returns_2', 'lag_returns_3',\n",
    "            'lag_price_1', 'lag_price_2', 'lag_price_3',\n",
    "            # Embedding features\n",
    "            'shop_embed', 'item_embed', 'category_embed'\n",
    "        ]\n",
    "        \n",
    "        # Reshape to (n_samples, n_features)\n",
    "        n_samples = avg_feature_weights.shape[0]\n",
    "        n_features = len(feature_names)\n",
    "        feature_importance = np.zeros((n_samples, n_features))\n",
    "        \n",
    "        # First 12 columns are numerical features\n",
    "        feature_importance[:, :12] = avg_feature_weights[:, 0, :12]\n",
    "        \n",
    "        # Last 3 columns are embeddings - sum importance across embedding dimensions\n",
    "        embed_dim = (avg_feature_weights.shape[2] - 12) // 3\n",
    "        feature_importance[:, 12] = np.sum(avg_feature_weights[:, 0, 12:12+embed_dim], axis=1)\n",
    "        feature_importance[:, 13] = np.sum(avg_feature_weights[:, 0, 12+embed_dim:12+2*embed_dim], axis=1)\n",
    "        feature_importance[:, 14] = np.sum(avg_feature_weights[:, 0, 12+2*embed_dim:], axis=1)\n",
    "        \n",
    "        # Create importance dataframe\n",
    "        importance_df = pd.DataFrame(feature_importance, columns=feature_names)\n",
    "        importance_df = pd.concat([interpret_df.reset_index(drop=True), importance_df], axis=1)\n",
    "        importance_df.to_csv(os.path.join(data_dir, 'feature_importance.csv'), index=False)\n",
    "        \n",
    "        # Plot average feature importance\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        sns.barplot(x=feature_names, y=np.mean(feature_importance, axis=0))\n",
    "        plt.title('Average Feature Importance')\n",
    "        plt.xlabel('Feature')\n",
    "        plt.ylabel('Importance Score')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(data_dir, 'avg_feature_importance.png'), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Feature importance analysis saved to {data_dir}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in feature importance analysis: {e}\")\n",
    "    \n",
    "    logger.info(\"All tasks completed successfully\")\n",
    "    \n",
    "    # Close TensorBoard writer if used\n",
    "    if writer:\n",
    "        writer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"=\" * 80)\n",
    "    logger.info(\"Starting Hierarchical Attention LSTM Forecasting\")\n",
    "    logger.info(\"=\" * 80)\n",
    "    \n",
    "    # Log system information\n",
    "    logger.info(f\"Python version: {sys.version}\")\n",
    "    logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "    logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        logger.info(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "        logger.info(f\"CUDA capability: {torch.cuda.get_device_capability(0)}\")\n",
    "        logger.info(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "    \n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error in main execution: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
